import os
import cv2
import uuid
import speech_recognition as sr
import time
from pathlib import Path
import sys

# Allow running as standalone script from tools/ by adding project root to sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from src.core.config import FACES_DIR, VOICES_DIR
from src.modules.face_recognition.face_recognition_module import FaceRecognitionModule
from src.modules.voice_recognition.voice_recognition_module import VoiceRecognitionModule
from src.utils.logger import Logger
from src.utils.utils import resize_image, draw_text_with_background

def main():
    """Main function to add a new user"""
    print("=== Th√™m ng∆∞·ªùi d√πng m·ªõi ===\n")
    
    # Get user information
    name = input("Nh·∫≠p t√™n ng∆∞·ªùi d√πng: ")
    
    # Generate a unique ID for the user
    user_id = str(uuid.uuid4())[:8]
    
    # Create directories for user data
    user_face_dir = FACES_DIR / user_id
    os.makedirs(user_face_dir, exist_ok=True)
    
    # Save metadata
    with open(user_face_dir / 'metadata.txt', 'w', encoding='utf-8') as f:
        f.write(name)
    
    # Initialize modules
    logger = Logger()
    face_module = FaceRecognitionModule(logger)
    voice_module = VoiceRecognitionModule(logger)
    
    # Capture face images
    capture_face_images(user_id, name, face_module)
    
    # Record voice samples
    record_voice_samples(user_id, name, voice_module)
    
    print(f"\nNg∆∞·ªùi d√πng {name} ƒë√£ ƒë∆∞·ª£c th√™m th√†nh c√¥ng v·ªõi ID: {user_id}")

def capture_face_images(user_id, name, face_module):
    """Capture face images for a new user"""
    print("\n=== Ch·ª•p ·∫£nh khu√¥n m·∫∑t ===")
    print("H·ªá th·ªëng s·∫Ω ch·ª•p 5 ·∫£nh khu√¥n m·∫∑t c·ªßa b·∫°n t·ª´ c√°c g√≥c ƒë·ªô kh√°c nhau.")
    print("Nh·∫•n SPACE ƒë·ªÉ ch·ª•p ·∫£nh, ESC ƒë·ªÉ h·ªßy.")
    
    # Initialize camera
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Kh√¥ng th·ªÉ m·ªü camera!")
        return
    
    # Create directory for user's face images
    user_dir = FACES_DIR / user_id
    os.makedirs(user_dir, exist_ok=True)
    
    # Capture 5 images
    image_count = 0
    max_images = 5
    
    # T·∫°o c·ª≠a s·ªï v√† ƒë·∫∑t ·ªü v·ªã tr√≠ c·ª• th·ªÉ
    window_name = f"ƒêƒÇNG K√ù: {name} - Ch·ª•p ·∫£nh khu√¥n m·∫∑t"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 800, 600)
    
    print(f"\nüì∏ B·∫Øt ƒë·∫ßu ch·ª•p ·∫£nh! (0/{max_images})")
    print("üí° C·ª≠a s·ªï camera ƒë√£ m·ªü - H√£y nh√¨n v√†o camera!")
    
    while image_count < max_images:
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ camera!")
            break
        
        # Resize frame for display
        display_frame = resize_image(frame, width=800)
        
        # Draw instructions v·ªõi nhi·ªÅu th√¥ng tin h∆°n
        instructions = [
            f"Ng∆∞·ªùi d√πng: {name}",
            f"·∫¢nh: {image_count}/{max_images}",
            "",
            "SPACE = Ch·ª•p | ESC = H·ªßy"
        ]
        
        y_offset = 30
        for i, text in enumerate(instructions):
            if text:  # B·ªè qua d√≤ng tr·ªëng
                draw_text_with_background(display_frame, text, (10, y_offset + i*35))
        
        # V·∫Ω khung h∆∞·ªõng d·∫´n v·ªã tr√≠ khu√¥n m·∫∑t
        height, width = display_frame.shape[:2]
        center_x, center_y = width // 2, height // 2
        face_box_size = 300
        
        # V·∫Ω khung oval h∆∞·ªõng d·∫´n
        cv2.ellipse(display_frame, (center_x, center_y), 
                   (face_box_size//2, int(face_box_size*0.7)), 
                   0, 0, 360, (0, 255, 0), 3)
        
        # Show frame
        cv2.imshow(window_name, display_frame)
        
        # Force window to front (Windows specific)
        try:
            cv2.setWindowProperty(window_name, cv2.WND_PROP_TOPMOST, 1)
        except:
            pass
        
        # Wait for key press
        key = cv2.waitKey(1)
        
        if key == 27:  # ESC key
            print("ƒê√£ h·ªßy ch·ª•p ·∫£nh!")
            break
        
        if key == 32:  # SPACE key
            print(f"\nüì∏ ƒêang ch·ª•p ·∫£nh {image_count+1}/{max_images}...")
            
            # Save image
            timestamp = int(time.time())
            image_path = user_dir / f"{timestamp}.jpg"
            cv2.imwrite(str(image_path), frame)
            
            # Add face to recognition module (module s·∫Ω t·ª± chuy·ªÉn BGR->RGB)
            if face_module.add_face(frame, user_id, name):
                image_count += 1
                print(f"‚úÖ ƒê√£ ch·ª•p ·∫£nh {image_count}/{max_images}")
                
                if image_count < max_images:
                    print(f"üëâ C√≤n {max_images - image_count} ·∫£nh n·ªØa. H√£y thay ƒë·ªïi g√≥c ƒë·ªô m·ªôt ch√∫t.")
                else:
                    print("üéâ ƒê√£ ch·ª•p ƒë·ªß ·∫£nh!")
            else:
                print("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh!")
                print("üí° Vui l√≤ng:")
                print("   - ƒê·∫£m b·∫£o khu√¥n m·∫∑t nh√¨n th·∫≥ng v√†o camera")
                print("   - C√≥ ƒë·ªß √°nh s√°ng")
                print("   - Kh√¥ng b·ªã che khu·∫•t")
            
            # Small delay to prevent multiple captures
            time.sleep(0.8)
    
    # Release camera and close windows
    print("\nüîÑ ƒêang ƒë√≥ng camera...")
    cap.release()
    cv2.destroyAllWindows()
    time.sleep(0.5)
    
    if image_count == max_images:
        print(f"‚úÖ Ho√†n t·∫•t ch·ª•p ·∫£nh cho {name}!")
    else:
        print(f"‚ö†Ô∏è Ch·ªâ ch·ª•p ƒë∆∞·ª£c {image_count}/{max_images} ·∫£nh")

def record_voice_samples(user_id, name, voice_module):
    """Record voice samples for a new user"""
    print("\n=== Ghi √¢m gi·ªçng n√≥i ===")
    print("H√£y ƒë·ªçc c√°c c√¢u sau ƒë√¢y ƒë·ªÉ h·ªá th·ªëng ghi nh·∫≠n gi·ªçng n√≥i c·ªßa b·∫°n.")
    
    # Phrases to record
    phrases = [
        "Xin ch√†o, t√¥i l√† " + name,
        "T√¥i mu·ªën ƒëƒÉng k√Ω m·ªôt cu·ªôc h·∫πn",
        "C·∫£m ∆°n b·∫°n r·∫•t nhi·ªÅu"
    ]
    
    # Initialize recognizer and microphone
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()
    
    # Adjust for ambient noise
    print("\nƒêang ƒëi·ªÅu ch·ªânh cho ti·∫øng ·ªìn xung quanh...")
    with microphone as source:
        recognizer.adjust_for_ambient_noise(source, duration=2)
    
    # Record each phrase
    keywords = []
    
    for i, phrase in enumerate(phrases):
        print(f"\nPhrase {i+1}/{len(phrases)}: {phrase}")
        print("Nh·∫•n Enter khi b·∫°n s·∫µn s√†ng n√≥i...")
        input()
        
        print("ƒêang ghi √¢m... H√£y n√≥i ngay b√¢y gi·ªù!")
        
        try:
            with microphone as source:
                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            
            print("ƒêang x·ª≠ l√Ω...")
            
            try:
                text = recognizer.recognize_google(audio, language="vi-VN")
                print(f"ƒê√£ nh·∫≠n d·∫°ng: {text}")
                
                # Extract keywords from recognized text
                words = text.split()
                keywords.extend([word for word in words if len(word) > 3])
                
            except sr.UnknownValueError:
                print("Kh√¥ng th·ªÉ nh·∫≠n d·∫°ng gi·ªçng n√≥i!")
            except sr.RequestError as e:
                print(f"L·ªói khi y√™u c·∫ßu k·∫øt qu·∫£ t·ª´ Google Speech Recognition: {e}")
        
        except Exception as e:
            print(f"L·ªói khi ghi √¢m: {e}")
    
    # Remove duplicates and save keywords
    keywords = list(set(keywords))
    
    if keywords:
        # Add voice pattern
        if voice_module.add_voice_pattern(user_id, name, keywords):
            print(f"\nƒê√£ ghi nh·∫≠n {len(keywords)} t·ª´ kh√≥a gi·ªçng n√≥i: {', '.join(keywords)}")
        else:
            print("Kh√¥ng th·ªÉ l∆∞u m·∫´u gi·ªçng n√≥i!")
    else:
        print("Kh√¥ng c√≥ t·ª´ kh√≥a n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ gi·ªçng n√≥i!")

if __name__ == "__main__":
    main()