# üìö T√ÄI LI·ªÜU H·ªÜ TH·ªêNG AI RECEPTIONIST - T·ªîNG QUAN TO√ÄN DI·ªÜN

> **Phi√™n b·∫£n:** 2.0  
> **Ng√†y c·∫≠p nh·∫≠t:** 06/12/2025  
> **T√°c gi·∫£:** AI Receptionist Development Team

---

## üìã M·ª§C L·ª§C

1. [T·ªïng Quan H·ªá Th·ªëng](#1-t·ªïng-quan-h·ªá-th·ªëng)
2. [Ki·∫øn Tr√∫c H·ªá Th·ªëng](#2-ki·∫øn-tr√∫c-h·ªá-th·ªëng)
3. [C√°c Module Ch√≠nh](#3-c√°c-module-ch√≠nh)
4. [Quy Tr√¨nh Ho·∫°t ƒê·ªông](#4-quy-tr√¨nh-ho·∫°t-ƒë·ªông)
5. [C·∫•u H√¨nh Chi Ti·∫øt](#5-c·∫•u-h√¨nh-chi-ti·∫øt)
6. [API v√† Interfaces](#6-api-v√†-interfaces)
7. [D·ªØ Li·ªáu v√† L∆∞u Tr·ªØ](#7-d·ªØ-li·ªáu-v√†-l∆∞u-tr·ªØ)
8. [B·∫£o M·∫≠t v√† Quy·ªÅn Ri√™ng T∆∞](#8-b·∫£o-m·∫≠t-v√†-quy·ªÅn-ri√™ng-t∆∞)
9. [Performance v√† T·ªëi ∆Øu](#9-performance-v√†-t·ªëi-∆∞u)
10. [Troubleshooting](#10-troubleshooting)

---

## 1. T·ªîNG QUAN H·ªÜ TH·ªêNG

### 1.1. Gi·ªõi Thi·ªáu

**AI Receptionist** l√† m·ªôt h·ªá th·ªëng l·ªÖ t√¢n th√¥ng minh s·ª≠ d·ª•ng c√¥ng ngh·ªá AI ƒë·ªÉ:
- Nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c
- T∆∞∆°ng t√°c b·∫±ng gi·ªçng n√≥i t·ª± nhi√™n
- Tr·∫£ l·ªùi c√¢u h·ªèi v√† h·ªó tr·ª£ kh√°ch h√†ng
- T·ª± ƒë·ªông ƒëƒÉng k√Ω ng∆∞·ªùi d√πng m·ªõi
- Ghi log v√† theo d√µi ho·∫°t ƒë·ªông

### 1.2. M·ª•c ƒê√≠ch S·ª≠ D·ª•ng

- **VƒÉn ph√≤ng**: Qu·∫£n l√Ω ra v√†o, ch√†o ƒë√≥n nh√¢n vi√™n
- **Kh√°ch s·∫°n**: Ti·∫øp ƒë√≥n kh√°ch, cung c·∫•p th√¥ng tin
- **C·ª≠a h√†ng**: Nh·∫≠n di·ªán kh√°ch quen, h·ªó tr·ª£ mua s·∫Øm
- **B·ªánh vi·ªán**: H∆∞·ªõng d·∫´n b·ªánh nh√¢n, qu·∫£n l√Ω l·ªãch h·∫πn
- **Tr∆∞·ªùng h·ªçc**: Qu·∫£n l√Ω h·ªçc sinh, ph·ª• huynh

### 1.3. T√≠nh NƒÉng Ch√≠nh

#### ‚úÖ Nh·∫≠n Di·ªán Khu√¥n M·∫∑t
- ƒê·ªô ch√≠nh x√°c: ~95% (ƒëi·ªÅu ki·ªán t·ªët)
- Th·ªùi gian ph·∫£n h·ªìi: < 1 gi√¢y
- H·ªó tr·ª£ nhi·ªÅu khu√¥n m·∫∑t c√πng l√∫c
- T·ª± ƒë·ªông ph√°t hi·ªán ng∆∞·ªùi m·ªõi

#### ‚úÖ Nh·∫≠n Di·ªán Gi·ªçng N√≥i
- H·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Anh
- ƒê·ªô ch√≠nh x√°c: ~90%
- X·ª≠ l√Ω nhi·ªÖu th√¥ng minh
- T√≠ch h·ª£p Google Speech API

#### ‚úÖ AI Chatbot
- Ph·∫£n h·ªìi th√¥ng minh
- H·ªçc t·ª´ ng·ªØ c·∫£nh
- ƒêa ng√¥n ng·ªØ
- Streaming TTS

#### ‚úÖ T·ª± ƒê·ªông ƒêƒÉng K√Ω
- Ph√°t hi·ªán ng∆∞·ªùi l·∫°
- Quy tr√¨nh ƒëƒÉng k√Ω nhanh (ch·ªâ 5 ·∫£nh)
- T·ª± ƒë·ªông c·∫≠p nh·∫≠t database
- Nh·∫≠n di·ªán ngay l·∫≠p t·ª©c

### 1.4. C√¥ng Ngh·ªá S·ª≠ D·ª•ng

| C√¥ng ngh·ªá | Phi√™n b·∫£n | M·ª•c ƒë√≠ch |
|-----------|-----------|----------|
| Python | 3.8+ | Ng√¥n ng·ªØ ch√≠nh |
| OpenCV | 4.8.1 | X·ª≠ l√Ω h√¨nh ·∫£nh |
| face_recognition | 1.3.0 | Nh·∫≠n di·ªán khu√¥n m·∫∑t |
| dlib | 19.24.1 | Machine learning |
| SpeechRecognition | 3.10.0 | Nh·∫≠n di·ªán gi·ªçng n√≥i |
| pyttsx3 | 2.90 | Text-to-Speech offline |
| gTTS | Latest | Text-to-Speech online |
| pygame | Latest | Ph√°t audio |
| Google Cloud APIs | Latest | Speech & TTS n√¢ng cao |

---

## 2. KI·∫æN TR√öC H·ªÜ TH·ªêNG

### 2.1. S∆° ƒê·ªì T·ªïng Quan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AI RECEPTIONIST SYSTEM                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Camera     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Face Module  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Recognition ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Input      ‚îÇ    ‚îÇ  Processing  ‚îÇ    ‚îÇ   Database   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Microphone  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Voice Module ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  AI Chatbot  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Input      ‚îÇ    ‚îÇ  Processing  ‚îÇ    ‚îÇ   Response   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ     UI       ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  Main Loop   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Logging    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Display    ‚îÇ    ‚îÇ  Controller  ‚îÇ    ‚îÇ   System     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2. C·∫•u Tr√∫c Th∆∞ M·ª•c

```
Receptionist_AI/
‚îÇ
‚îú‚îÄ‚îÄ main.py                          # Entry point ch√≠nh
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencies
‚îú‚îÄ‚îÄ .env.example                     # C·∫•u h√¨nh m·∫´u
‚îú‚îÄ‚îÄ .env                            # C·∫•u h√¨nh th·ª±c t·∫ø (kh√¥ng commit)
‚îÇ
‚îú‚îÄ‚îÄ src/                            # Source code ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Core logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py              # C·∫•u h√¨nh to√†n c·ª•c
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main_streaming.py     # Main system controller
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inline_registration.py # ƒêƒÉng k√Ω ng∆∞·ªùi d√πng
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ modules/                    # C√°c module ch·ª©c nƒÉng
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ face_recognition/      # Nh·∫≠n di·ªán khu√¥n m·∫∑t
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ face_recognition_module.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ voice_recognition/     # Nh·∫≠n di·ªán gi·ªçng n√≥i
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ voice_recognition_module.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai_chatbot/           # AI Chatbot
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai_chatbot_integration.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tts/                  # Text-to-Speech
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ streaming_tts_module.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ enhanced_tts_module.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ui/                        # User Interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Utilities
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py             # Logging system
‚îÇ       ‚îî‚îÄ‚îÄ utils.py              # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ tools/                         # Tools v√† scripts
‚îÇ   ‚îî‚îÄ‚îÄ add_user.py               # Tool ƒëƒÉng k√Ω th·ªß c√¥ng
‚îÇ
‚îú‚îÄ‚îÄ data/                          # D·ªØ li·ªáu h·ªá th·ªëng
‚îÇ   ‚îú‚îÄ‚îÄ faces/                    # D·ªØ li·ªáu khu√¥n m·∫∑t
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [user_id]/           # Th∆∞ m·ª•c m·ªói ng∆∞·ªùi
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata.txt     # T√™n ng∆∞·ªùi d√πng
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.jpg            # ·∫¢nh khu√¥n m·∫∑t
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ encodings.pkl        # Face encodings cache
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ voices/                   # D·ªØ li·ªáu gi·ªçng n√≥i
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patterns.pkl         # Voice patterns
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ logs/                     # Logs
‚îÇ       ‚îú‚îÄ‚îÄ system_YYYYMMDD.log
‚îÇ       ‚îú‚îÄ‚îÄ reception_YYYYMMDD.log
‚îÇ       ‚îî‚îÄ‚îÄ detailed_YYYYMMDD.log
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # T√†i li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ README_GOOGLE_CLOUD.md
‚îÇ   ‚îî‚îÄ‚îÄ README_STREAMING.md
‚îÇ
‚îî‚îÄ‚îÄ tests/                         # Tests (future)
```

---

## 3. C√ÅC MODULE CH√çNH

### 3.1. Face Recognition Module

**File:** `src/modules/face_recognition/face_recognition_module.py`

#### Ch·ª©c nƒÉng:
- Load v√† qu·∫£n l√Ω face encodings
- Detect faces trong frame
- So s√°nh v√† nh·∫≠n di·ªán
- Th√™m ng∆∞·ªùi d√πng m·ªõi
- L·ªçc duplicate faces

#### Thu·∫≠t to√°n:
```python
# 1. Face Detection
face_locations = face_recognition.face_locations(frame, model='hog')

# 2. Face Encoding
face_encodings = face_recognition.face_encodings(frame, face_locations)

# 3. Face Comparison
distances = face_recognition.face_distance(known_encodings, face_encoding)

# 4. Decision Making
if distance <= TOLERANCE and confidence >= MIN_CONFIDENCE:
    # Matched!
```

#### C·∫•u h√¨nh quan tr·ªçng:

```python
FACE_RECOGNITION_TOLERANCE = 0.55      # Ng∆∞·ª°ng distance (0.0-1.0)
MIN_CONFIDENCE_THRESHOLD = 0.50        # Ng∆∞·ª°ng confidence (0.0-1.0)
FACE_RECOGNITION_MODEL = 'hog'         # 'hog' ho·∫∑c 'cnn'
MIN_FACE_SIZE = 80                     # K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (pixels)
FACE_DETECTION_UPSAMPLE = 1            # S·ªë l·∫ßn upsample
ENABLE_PREPROCESSING = False           # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
```

#### Methods ch√≠nh:

**`load_known_faces()`**
- Load face encodings t·ª´ file ho·∫∑c images
- Cache v√†o `encodings.pkl` ƒë·ªÉ tƒÉng t·ªëc

**`recognize_faces(frame)`**
- Nh·∫≠n di·ªán t·∫•t c·∫£ khu√¥n m·∫∑t trong frame
- Tr·∫£ v·ªÅ list c√°c face data v·ªõi confidence

**`add_face(face_image, person_id, person_name)`**
- Th√™m khu√¥n m·∫∑t m·ªõi v√†o database
- L∆∞u ·∫£nh v√† metadata
- C·∫≠p nh·∫≠t encodings

**`_remove_duplicate_faces(results)`**
- Lo·∫°i b·ªè khu√¥n m·∫∑t tr√πng l·∫∑p
- Gi·ªØ face c√≥ confidence cao nh·∫•t

### 3.2. Voice Recognition Module

**File:** `src/modules/voice_recognition/voice_recognition_module.py`

#### Ch·ª©c nƒÉng:
- Nh·∫≠n di·ªán gi·ªçng n√≥i th√†nh text
- Pattern matching v·ªõi voice patterns
- Qu·∫£n l√Ω voice patterns database
- Background listening

#### Engine:
- **Google Speech Recognition API** (m·∫∑c ƒë·ªãnh)
- **Google Cloud Speech API** (t√πy ch·ªçn)

#### C·∫•u h√¨nh:
```python
VOICE_ENERGY_THRESHOLD = 450           # Ng∆∞·ª°ng nƒÉng l∆∞·ª£ng
VOICE_PAUSE_THRESHOLD = 0.5            # Th·ªùi gian pause (s)
VOICE_PHRASE_TIME_LIMIT = 3            # Th·ªùi gian t·ªëi ƒëa (s)
VOICE_TIMEOUT = 0.5                    # Timeout (s)
VOICE_CONFIDENCE_THRESHOLD = 0.7       # Ng∆∞·ª°ng confidence
```

#### Methods ch√≠nh:

**`listen_for_command(timeout, phrase_time_limit)`**
- L·∫Øng nghe v√† nh·∫≠n di·ªán gi·ªçng n√≥i
- Tr·∫£ v·ªÅ text ho·∫∑c None

**`recognize_speech(audio)`**
- Chuy·ªÉn audio th√†nh text
- Match v·ªõi known patterns
- Tr·∫£ v·ªÅ person_id n·∫øu match

**`add_voice_pattern(person_id, person_name, keywords)`**
- Th√™m voice pattern m·ªõi
- L∆∞u v√†o `patterns.pkl`

### 3.3. TTS (Text-to-Speech) Module

**File:** `src/modules/tts/streaming_tts_module.py`

#### Ch·ª©c nƒÉng:
- Chuy·ªÉn text th√†nh gi·ªçng n√≥i
- Streaming audio playback
- Queue management v·ªõi priority
- Caching audio files

#### Engines:

**1. Auto Selection (Th√¥ng minh)**
```python
if internet_available and gTTS_available:
    use gTTS  # Ch·∫•t l∆∞·ª£ng cao
else:
    use pyttsx3  # Offline fallback
```

**2. Google TTS (gTTS)**
- Gi·ªçng n√≥i t·ª± nhi√™n
- H·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët
- C·∫ßn internet

**3. pyttsx3**
- Ho·∫°t ƒë·ªông offline
- Ph·∫£n h·ªìi nhanh
- Gi·ªçng √≠t t·ª± nhi√™n h∆°n

#### Methods ch√≠nh:

**`speak_async(text, priority)`**
- Th√™m v√†o queue
- X·ª≠ l√Ω background

**`speak_immediate(text)`**
- Ng·∫Øt gi·ªçng hi·ªán t·∫°i
- N√≥i ngay l·∫≠p t·ª©c

**`stop_current_speech()`**
- D·ª´ng gi·ªçng n√≥i
- Clear queue

### 3.4. AI Chatbot Module

**File:** `src/modules/ai_chatbot/ai_chatbot_integration.py`

#### Ch·ª©c nƒÉng:
- Ph√¢n t√≠ch intent t·ª´ input
- Generate response ph√π h·ª£p
- Qu·∫£n l√Ω conversation history
- T√≠ch h·ª£p TTS

#### Knowledge Base:

```python
knowledge_base = {
    "greetings": {
        "patterns": ["xin ch√†o", "hello", "ch√†o"],
        "responses": ["T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?", ...]
    },
    "thanks": {...},
    "goodbye": {...},
    "time": {...},
    "weather": {...},
    "help": {...},
    "name": {...}
}
```

#### Methods ch√≠nh:

**`process_input(user_input)`**
- Ph√¢n t√≠ch intent
- Generate response
- Th√™m personality

**`speak_response(user_input, priority)`**
- Process v√† n√≥i response

**`speak_direct(message, priority)`**
- N√≥i tr·ª±c ti·∫øp kh√¥ng qua AI

### 3.5. Inline Registration Module

**File:** `src/core/inline_registration.py`

#### Ch·ª©c nƒÉng:
- ƒêƒÉng k√Ω ng∆∞·ªùi d√πng m·ªõi inline
- Ch·ª•p 5 ·∫£nh t·ª± ƒë·ªông
- Qu·∫£n l√Ω registration state
- T·ª± ƒë·ªông reload database

#### Quy tr√¨nh:
```
1. start() ‚Üí Kh·ªüi t·∫°o ƒëƒÉng k√Ω
2. get_name ‚Üí Nh·∫≠n t√™n qua gi·ªçng n√≥i
3. capture_face ‚Üí Ch·ª•p 5 ·∫£nh (1.2s/·∫£nh)
4. completed ‚Üí L∆∞u v√† reload
5. reset() ‚Üí D·ªçn d·∫πp
```

#### State Machine:
```python
state = {
    'step': 'get_name',  # get_name ‚Üí capture_face ‚Üí completed
    'name': '',
    'face_count': 0,
    'max_faces': 5
}
```

#### Methods ch√≠nh:

**`start()`**
- B·∫Øt ƒë·∫ßu ƒëƒÉng k√Ω
- T·∫°o user_id v√† th∆∞ m·ª•c

**`process(frame, detected_faces)`**
- X·ª≠ l√Ω t·ª´ng step
- Ki·ªÉm tra ng∆∞·ªùi quen (h·ªßy n·∫øu c·∫ßn)

**`handle_voice_input(text)`**
- X·ª≠ l√Ω input gi·ªçng n√≥i
- Tr√≠ch xu·∫•t t√™n

**`complete()`**
- L∆∞u metadata
- ƒê√°nh d·∫•u ho√†n t·∫•t

---

## 4. QUY TR√åNH HO·∫†T ƒê·ªòNG

### 4.1. Main Loop

**File:** `src/core/main_streaming.py`

```python
while running:
    # 1. Capture frame
    ret, frame = camera.read()
    
    # 2. Face recognition
    faces = face_module.recognize_faces(frame)
    
    # 3. Process faces
    process_face_recognition(faces)
    
    # 4. Handle registration
    if registration.is_active:
        should_cancel = registration.process(frame, faces)
        if should_cancel:
            registration.cancel()
    
    # 5. Update UI
    ui.update_frame(frame)
    ui.render()
    
    # 6. Handle keyboard input
    key = cv2.waitKey(1)
```

### 4.2. Nh·∫≠n Di·ªán Ng∆∞·ªùi Quen

```
Camera ‚Üí Detect Face ‚Üí Extract Encoding
    ‚Üì
Compare with Database
    ‚Üì
distance <= TOLERANCE?
    ‚Üì YES
confidence >= MIN_CONFIDENCE?
    ‚Üì YES
MATCHED! ‚Üí Log ‚Üí Greet
```

### 4.3. Ph√°t Hi·ªán Ng∆∞·ªùi M·ªõi

```
Camera ‚Üí Detect Face ‚Üí Extract Encoding
    ‚Üì
Compare with Database
    ‚Üì
No Match (Unknown)
    ‚Üì
Different from current_face?
    ‚Üì YES
New Person Detected!
    ‚Üì
Start Registration
```

### 4.4. Quy Tr√¨nh ƒêƒÉng K√Ω

```
1. Detect Unknown Face
    ‚Üì
2. Speak: "Xin ch√†o! B·∫°n l√† ng∆∞·ªùi m·ªõi..."
    ‚Üì
3. Speak: "Vui l√≤ng n√≥i t√™n c·ªßa b·∫°n"
    ‚Üì
4. Listen for Name
    ‚Üì
5. Extract Name from Speech
    ‚Üì
6. Speak: "Xin ch√†o [T√™n]! B√¢y gi·ªù ch·ª•p ·∫£nh..."
    ‚Üì
7. Auto Capture 5 Photos (1.2s interval)
    ‚Üì
8. Save Photos + Metadata
    ‚Üì
9. Update encodings.pkl
    ‚Üì
10. Reload Face Database
    ‚Üì
11. Speak: "Ho√†n t·∫•t! ƒêƒÉng k√Ω th√†nh c√¥ng!"
    ‚Üì
12. Reset Registration State
```

### 4.5. Voice Command Processing

```
Microphone ‚Üí Listen
    ‚Üì
Capture Audio
    ‚Üì
Google Speech API
    ‚Üì
Text Output
    ‚Üì
If Registration Active:
    ‚Üí Handle Registration Input
Else:
    ‚Üí AI Chatbot Process
    ‚Üì
Generate Response
    ‚Üì
TTS Speak Response
```

---

## 5. C·∫§U H√åNH CHI TI·∫æT

### 5.1. File .env

```bash
# ============================================
# FACE RECOGNITION SETTINGS
# ============================================

# Tolerance: Ng∆∞·ª°ng distance ƒë·ªÉ ch·∫•p nh·∫≠n match
# 0.6 = default (c√¢n b·∫±ng)
# 0.5 = ch·∫∑t (√≠t false positive)
# 0.7 = l·ªèng (d·ªÖ nh·∫≠n di·ªán nh∆∞ng c√≥ th·ªÉ nh·∫ßm)
FACE_RECOGNITION_TOLERANCE=0.55

# Confidence t·ªëi thi·ªÉu (0.0 - 1.0)
# C√†ng cao c√†ng ch·∫∑t ch·∫Ω
MIN_CONFIDENCE_THRESHOLD=0.50

# Model: 'hog' (nhanh, CPU) ho·∫∑c 'cnn' (ch√≠nh x√°c, GPU)
FACE_RECOGNITION_MODEL=hog

# K√≠ch th∆∞·ªõc khu√¥n m·∫∑t t·ªëi thi·ªÉu (pixels)
MIN_FACE_SIZE=80

# S·ªë l·∫ßn upsample khi detect
# 1 = nhanh, 2 = ch√≠nh x√°c h∆°n
FACE_DETECTION_UPSAMPLE=1

# B·∫≠t preprocessing (c·∫£i thi·ªán √°nh s√°ng)
# true/false
ENABLE_PREPROCESSING=false

# Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh ng∆∞·ªùi KH√ÅC
FACE_CHANGE_THRESHOLD=0.55

# ============================================
# VOICE RECOGNITION SETTINGS
# ============================================

# Ng∆∞·ª°ng nƒÉng l∆∞·ª£ng √¢m thanh
VOICE_ENERGY_THRESHOLD=450

# Th·ªùi gian pause ƒë·ªÉ k·∫øt th√∫c c√¢u (seconds)
VOICE_PAUSE_THRESHOLD=0.5

# Th·ªùi gian t·ªëi ƒëa cho m·ªôt c√¢u (seconds)
VOICE_PHRASE_TIME_LIMIT=3

# Timeout ch·ªù √¢m thanh (seconds)
VOICE_TIMEOUT=0.5

# Ng∆∞·ª°ng confidence
VOICE_CONFIDENCE_THRESHOLD=0.7

# ============================================
# REGISTRATION SETTINGS
# ============================================

# Timeout cho voice input khi ƒëƒÉng k√Ω
REGISTER_VOICE_TIMEOUT=2.0

# Th·ªùi gian t·ªëi ƒëa cho c√¢u khi ƒëƒÉng k√Ω
REGISTER_VOICE_PHRASE_TIME_LIMIT=6.0

# Th·ªùi gian calibrate microphone
REGISTER_VOICE_CALIBRATE_DURATION=1.0

# ============================================
# GOOGLE CLOUD SETTINGS (Optional)
# ============================================

# Path to credentials JSON file
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json

# Project ID
GOOGLE_CLOUD_PROJECT_ID=your-project-id

# Region (g·∫ßn VN ƒë·ªÉ gi·∫£m latency)
GOOGLE_CLOUD_REGION=asia-southeast1

# S·ª≠ d·ª•ng Google Cloud Voice (true/false)
USE_GOOGLE_CLOUD_VOICE=false

# ============================================
# SYSTEM SETTINGS
# ============================================

# Ng√¥n ng·ªØ: 'vi' ho·∫∑c 'en'
LANGUAGE=vi

# Kho·∫£ng th·ªùi gian t·ªëi thi·ªÉu gi·ªØa 2 log (seconds)
LOG_INTERVAL=30

# Target FPS
TARGET_FPS=60

# UI Settings
UI_WINDOW_NAME=AI Receptionist
UI_WINDOW_WIDTH=800
UI_WINDOW_HEIGHT=600
```

### 5.2. Config.py Structure

**File:** `src/core/config.py`

```python
# Base paths
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
FACES_DIR = DATA_DIR / 'faces'
VOICES_DIR = DATA_DIR / 'voices'
LOGS_DIR = DATA_DIR / 'logs'
RESOURCES_DIR = BASE_DIR / 'resources'

# Load from .env
FACE_RECOGNITION_TOLERANCE = float(os.getenv('FACE_RECOGNITION_TOLERANCE', 0.55))
MIN_CONFIDENCE_THRESHOLD = float(os.getenv('MIN_CONFIDENCE_THRESHOLD', 0.50))
# ... etc
```

---

## 6. API V√Ä INTERFACES

### 6.1. Face Recognition API

```python
# Initialize
face_module = FaceRecognitionModule(logger)

# Load faces
face_module.load_known_faces()

# Recognize
faces = face_module.recognize_faces(frame)
# Returns: [{'name': str, 'person_id': str, 'confidence': float, 'location': tuple}]

# Add new face
success = face_module.add_face(face_image, person_id, person_name)
```

### 6.2. Voice Recognition API

```python
# Initialize
voice_module = VoiceRecognitionModule(logger)

# Listen
text = voice_module.listen_for_command(timeout=2, phrase_time_limit=4)
# Returns: str or None

# Add pattern
voice_module.add_voice_pattern(person_id, person_name, keywords)
```

### 6.3. TTS API

```python
# Initialize
tts = StreamingTTSModule(engine_type="auto")

# Speak async
tts.speak_async("Xin ch√†o!", priority="normal")

# Speak immediate (interrupt)
tts.speak_immediate("Kh·∫©n c·∫•p!")

# Stop
tts.stop_current_speech()

# Check status
is_busy = tts.is_busy()
```

### 6.4. AI Chatbot API

```python
# Initialize
chatbot = AIReceptionistChatbot(tts_engine="auto")

# Process and speak
response = chatbot.speak_response(user_input, priority="normal")

# Direct speak
chatbot.speak_direct("Hello!", priority="high")

# Interrupt
chatbot.interrupt_and_respond("Urgent message!")
```

### 6.5. Registration API

```python
# Initialize
registration = InlineRegistration(face_module, voice_module, logger, ui)

# Start
success = registration.start()

# Process
should_cancel = registration.process(frame, detected_faces)

# Handle voice
response = registration.handle_voice_input(text)

# Complete
success = registration.complete()

# Cancel
registration.cancel()

# Reset
registration.reset()
```

---

## 7. D·ªÆ LI·ªÜU V√Ä L∆ØU TR·ªÆ

### 7.1. Face Data Structure

```
data/faces/
‚îú‚îÄ‚îÄ [user_id_1]/              # UUID 8 k√Ω t·ª±
‚îÇ   ‚îú‚îÄ‚îÄ metadata.txt          # T√™n ng∆∞·ªùi d√πng (UTF-8)
‚îÇ   ‚îú‚îÄ‚îÄ 1234567890.jpg       # ·∫¢nh 1 (timestamp)
‚îÇ   ‚îú‚îÄ‚îÄ 1234567891.jpg       # ·∫¢nh 2
‚îÇ   ‚îú‚îÄ‚îÄ 1234567892.jpg       # ·∫¢nh 3
‚îÇ   ‚îú‚îÄ‚îÄ 1234567893.jpg       # ·∫¢nh 4
‚îÇ   ‚îî‚îÄ‚îÄ 1234567894.jpg       # ·∫¢nh 5
‚îú‚îÄ‚îÄ [user_id_2]/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ encodings.pkl             # Cache t·∫•t c·∫£ encodings
```

**encodings.pkl format:**
```python
{
    'encodings': [array1, array2, ...],  # Face encodings (128-d vectors)
    'names': ['Name1', 'Name2', ...],    # T√™n t∆∞∆°ng ·ª©ng
    'ids': ['id1', 'id2', ...]           # User IDs
}
```

### 7.2. Voice Data Structure

```
data/voices/
‚îî‚îÄ‚îÄ patterns.pkl              # Voice patterns
```

**patterns.pkl format:**
```python
{
    'user_id_1': {
        'name': 'Name1',
        'keywords': ['keyword1', 'keyword2', ...]
    },
    'user_id_2': {...}
}
```

### 7.3. Logs Structure

```
data/logs/
‚îú‚îÄ‚îÄ system_20251206.log       # System events
‚îú‚îÄ‚îÄ reception_20251206.log    # Recognition events (CSV)
‚îî‚îÄ‚îÄ detailed_20251206.log     # Detailed logs (JSON)
```

**reception log format (CSV):**
```csv
timestamp,person_id,person_name,recognition_type,confidence,action
2025-12-06 15:30:45,abc123,John,face,0.95,detected
```

**detailed log format (JSON):**
```json
{
  "logs": [
    {
      "timestamp": "2025-12-06 15:30:45",
      "person_id": "abc123",
      "person_name": "John",
      "recognition_type": "face",
      "confidence": 0.95,
      "action": "detected"
    }
  ]
}
```

---

## 8. B·∫¢O M·∫¨T V√Ä QUY·ªÄN RI√äNG T∆Ø

### 8.1. L∆∞u Tr·ªØ D·ªØ Li·ªáu

- **Local Storage**: T·∫•t c·∫£ d·ªØ li·ªáu l∆∞u local
- **No Cloud Upload**: Kh√¥ng upload ·∫£nh/video l√™n cloud
- **Encrypted**: C√≥ th·ªÉ m√£ h√≥a th∆∞ m·ª•c data/

### 8.2. API Keys

- Google Speech API: Mi·ªÖn ph√≠ v·ªõi gi·ªõi h·∫°n
- Google Cloud: C·∫ßn credentials (t√πy ch·ªçn)
- Kh√¥ng l∆∞u API keys trong code

### 8.3. GDPR Compliance

- **Right to Access**: User c√≥ th·ªÉ xem d·ªØ li·ªáu
- **Right to Delete**: X√≥a th∆∞ m·ª•c user_id
- **Right to Portability**: Export d·ªØ li·ªáu
- **Consent**: C·∫ßn consent tr∆∞·ªõc khi ƒëƒÉng k√Ω

### 8.4. Best Practices

```python
# 1. Kh√¥ng commit .env
.gitignore:
.env
data/

# 2. M√£ h√≥a sensitive data
from cryptography.fernet import Fernet
key = Fernet.generate_key()
cipher = Fernet(key)

# 3. Gi·ªõi h·∫°n quy·ªÅn truy c·∫≠p
os.chmod('data/', 0o700)

# 4. Audit logs
logger.log_system_event('access', f'User {user_id} accessed')
```

---

## 9. PERFORMANCE V√Ä T·ªêI ∆ØU

### 9.1. Metrics

| Metric | Target | Actual |
|--------|--------|--------|
| Face Recognition | < 1s | ~0.5s |
| Voice Recognition | < 3s | ~2s |
| TTS Response | < 2s | ~1s |
| FPS | 30-60 | 40-50 |
| CPU Usage | < 50% | 30-40% |
| RAM Usage | < 1GB | 500-800MB |

### 9.2. Optimization Techniques

#### Face Recognition:
```python
# 1. Resize frame
small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)

# 2. Use HOG instead of CNN
model = 'hog'  # 10x faster

# 3. Cache encodings
encodings.pkl  # Load once, use many times

# 4. Skip frames
if frame_count % 2 == 0:  # Process every 2nd frame
    recognize_faces()
```

#### Voice Recognition:
```python
# 1. Adjust energy threshold
recognizer.energy_threshold = 450

# 2. Dynamic threshold
recognizer.dynamic_energy_threshold = True

# 3. Shorter timeout
timeout = 0.5  # seconds
```

#### TTS:
```python
# 1. Cache audio files
self.cache = {}  # Frequently used phrases

# 2. Background processing
threading.Thread(target=speak_worker)

# 3. Queue management
priority_queue = queue.PriorityQueue()
```

### 9.3. Hardware Requirements

**Minimum:**
- CPU: Intel i3 / AMD Ryzen 3
- RAM: 4GB
- Webcam: 720p
- Microphone: Any

**Recommended:**
- CPU: Intel i5 / AMD Ryzen 5
- RAM: 8GB
- Webcam: 1080p
- Microphone: Noise-cancelling
- GPU: Optional (for CNN model)

---

## 10. TROUBLESHOOTING

### 10.1. Kh√¥ng Nh·∫≠n Di·ªán ƒê∆∞·ª£c

**Tri·ªáu ch·ª©ng:** Lu√¥n hi·ªán "Unknown"

**Nguy√™n nh√¢n & Gi·∫£i ph√°p:**

1. **√Ånh s√°ng k√©m**
   - Ki·ªÉm tra: ƒê·ªß s√°ng, kh√¥ng qu√° t·ªëi/ch√≥i
   - Gi·∫£i ph√°p: B·∫≠t ƒë√®n, tr√°nh backlight

2. **Tolerance qu√° ch·∫∑t**
   ```bash
   # .env
   FACE_RECOGNITION_TOLERANCE=0.60  # TƒÉng l√™n
   MIN_CONFIDENCE_THRESHOLD=0.45    # Gi·∫£m xu·ªëng
   ```

3. **·∫¢nh ƒëƒÉng k√Ω k√©m ch·∫•t l∆∞·ª£ng**
   - ƒêƒÉng k√Ω l·∫°i v·ªõi ·∫£nh t·ªët h∆°n
   - Nhi·ªÅu g√≥c ƒë·ªô kh√°c nhau

4. **Cache c≈©**
   ```bash
   # X√≥a cache
   del data/faces/encodings.pkl
   # Restart app
   ```

### 10.2. Nh·∫≠n Di·ªán Sai

**Tri·ªáu ch·ª©ng:** Nh·∫≠n di·ªán nh·∫ßm ng∆∞·ªùi

**Gi·∫£i ph√°p:**

1. **TƒÉng ƒë·ªô ch·∫∑t ch·∫Ω**
   ```bash
   FACE_RECOGNITION_TOLERANCE=0.45
   MIN_CONFIDENCE_THRESHOLD=0.60
   ```

2. **X√≥a ng∆∞·ªùi b·ªã nh·∫ßm**
   ```bash
   # X√≥a th∆∞ m·ª•c
   rm -rf data/faces/[wrong_user_id]
   # Reload
   ```

3. **Ki·ªÉm tra duplicate**
   - M·ªôt ng∆∞·ªùi c√≥ nhi·ªÅu ID
   - Merge ho·∫∑c x√≥a duplicate

### 10.3. Camera Kh√¥ng Ho·∫°t ƒê·ªông

**Tri·ªáu ch·ª©ng:** "Cannot open camera"

**Gi·∫£i ph√°p:**

1. **App kh√°c ƒëang d√πng camera**
   - ƒê√≥ng Zoom, Skype, etc.
   - Restart app

2. **Quy·ªÅn truy c·∫≠p**
   - Windows: Settings ‚Üí Privacy ‚Üí Camera
   - Mac: System Preferences ‚Üí Security ‚Üí Camera

3. **Driver**
   - C·∫≠p nh·∫≠t camera driver
   - Th·ª≠ camera kh√°c

### 10.4. Kh√¥ng Nghe ƒê∆∞·ª£c Gi·ªçng N√≥i

**Tri·ªáu ch·ª©ng:** "Speech was unintelligible"

**Gi·∫£i ph√°p:**

1. **Microphone kh√¥ng ho·∫°t ƒë·ªông**
   - Ki·ªÉm tra k·∫øt n·ªëi
   - Test microphone

2. **Nhi·ªÖu qu√° l·ªõn**
   ```bash
   VOICE_ENERGY_THRESHOLD=600  # TƒÉng l√™n
   ```

3. **N√≥i kh√¥ng r√µ**
   - N√≥i to h∆°n
   - N√≥i ch·∫≠m h∆°n
   - Gi·∫£m ti·∫øng ·ªìn

4. **Internet**
   - Google Speech API c·∫ßn internet
   - Ki·ªÉm tra k·∫øt n·ªëi

### 10.5. TTS Kh√¥ng Ph√°t √Çm

**Tri·ªáu ch·ª©ng:** Kh√¥ng c√≥ gi·ªçng n√≥i

**Gi·∫£i ph√°p:**

1. **Loa t·∫Øt ti·∫øng**
   - Ki·ªÉm tra volume
   - Unmute

2. **Engine l·ªói**
   ```python
   # Th·ª≠ engine kh√°c
   tts = StreamingTTSModule(engine_type="pyttsx3")
   ```

3. **pygame l·ªói**
   ```bash
   pip uninstall pygame
   pip install pygame
   ```

### 10.6. Performance K√©m

**Tri·ªáu ch·ª©ng:** FPS th·∫•p, lag

**Gi·∫£i ph√°p:**

1. **Gi·∫£m resolution**
   ```python
   camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
   camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
   ```

2. **Skip frames**
   ```python
   if frame_count % 3 == 0:  # Process every 3rd frame
       recognize_faces()
   ```

3. **ƒê√≥ng app kh√°c**
   - Gi·∫£i ph√≥ng CPU/RAM
   - ƒê√≥ng browser tabs

4. **Upgrade hardware**
   - Th√™m RAM
   - CPU m·∫°nh h∆°n

### 10.7. ƒêƒÉng K√Ω B·ªã H·ªßy

**Tri·ªáu ch·ª©ng:** "Ph√°t hi·ªán ng∆∞·ªùi quen - H·ªßy ƒëƒÉng k√Ω"

**Gi·∫£i ph√°p:**

1. **Ng∆∞·ªùi kh√°c v√†o frame**
   - ƒê·∫£m b·∫£o ch·ªâ 1 ng∆∞·ªùi
   - ƒêƒÉng k√Ω l·∫°i

2. **Nh·∫≠n di·ªán nh·∫ßm**
   - TƒÉng tolerance t·∫°m th·ªùi
   - ƒêƒÉng k√Ω xong m·ªõi gi·∫£m

### 10.8. L·ªói Import

**Tri·ªáu ch·ª©ng:** "ModuleNotFoundError"

**Gi·∫£i ph√°p:**

```bash
# Reinstall dependencies
pip install -r requirements.txt

# Ho·∫∑c c√†i t·ª´ng package
pip install opencv-python
pip install face-recognition
pip install SpeechRecognition
pip install pyttsx3
```

### 10.9. Encoding Error

**Tri·ªáu ch·ª©ng:** "UnicodeDecodeError"

**Gi·∫£i ph√°p:**

```python
# ƒê·∫£m b·∫£o UTF-8
with open(file, 'r', encoding='utf-8') as f:
    content = f.read()

# Windows: Chcp 65001
```

### 10.10. Log Files Qu√° L·ªõn

**Gi·∫£i ph√°p:**

```bash
# X√≥a log c≈©
rm data/logs/*_202411*.log

# Ho·∫∑c archive
tar -czf logs_backup.tar.gz data/logs/
rm data/logs/*.log
```

---

## üìû H·ªñ TR·ª¢ V√Ä LI√äN H·ªÜ

### B√°o L·ªói
- T·∫°o issue tr√™n GitHub
- M√¥ t·∫£ chi ti·∫øt v·∫•n ƒë·ªÅ
- Attach logs n·∫øu c√≥

### ƒê√≥ng G√≥p
- Fork repository
- T·∫°o feature branch
- Submit pull request

### T√†i Li·ªáu Th√™m
- `docs/README_GOOGLE_CLOUD.md` - Google Cloud setup
- `docs/README_STREAMING.md` - Streaming architecture
- `README.md` - Quick start guide

---

**¬© 2025 AI Receptionist Development Team**  
**Version:** 2.0  
**Last Updated:** 06/12/2025
